git remote set-url origin git@github.com:danchurch/getConcsFromUrl.git

## Roo's Brother Marshall has found the url for the concession layer, probably.
## let's confirm.

## the interactive gui is here:
https://gis-sigde.maps.arcgis.com/apps/webappviewer/index.html?id=8b53f9388c034b5e8e3147f03583d7ec&fbclid=IwAR2XobS46Szpz4A7IGroPuLCZh5GSJC

## the arcgis server RESTful access starts here
https://geovisorm.controlrecursosyenergia.gob.ec/arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/MapServer/0

## the fear is that he has an old layer, leftover from the days when they were using the old 
## geovisor app:
https://geo.controlminero.gob.ec:1026/geo_visor/

## but I think he is aware of that old dataset. I guess the only way to check is 
## build up a json by querying the url he found. 

## one query for 1000 random objects that Marshall generated:

https://geovisorm.controlrecursosyenergia.gob.ec/arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/MapServer/0/query?where=0%3D0&outFields=%2A&f=json

https://geovisorm.controlrecursosyenergia.gob.ec/arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/MapServer/0/query?where=0%3D0&outFields=%2A&f=pjson


## to get just ids, would this work?:

python3

import requests, re, json, pprint
import pandas as pd

concIDs = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
"arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
"MapServer/0/query?where=0%3D0&outFields=%2A&f=json&returnIdsOnly=true")

## how do use these ids to get us the geometric objects?
## we need to break this up into requests of less than 1000


concIDs.text

type(concIDs.text)

aa = concIDs.text.split(',')
bb = pd.Series(aa)

allIDs = bb.drop([0,1,bb.index[-1]]).reset_index(drop=True)


## can we make a request for just the first ten objects?

cc = allIDs.iloc[0:10].to_string(index=False)
patt = re.compile('\n +')
dd = patt.sub(',', cc).strip()



allIDs.iloc[0:10].values

allIDs.iloc[0:10].to_list()

first1 = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=json"
                       "&objectIds=10915,140010"
                       "&returnIdsOnly=true"
                      )


## other file formats are mentioned: 
## https://sampleserver1.arcgisonline.com/ArcGIS/SDK/REST/formattypes.html

ids=allIDs[0:3]

ids=dd
aa = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=json"
                       "&geometryType=esriGeometryPolygon"
                       f"&objectIds={ids}"
                       "&returnIdsOnly=true"
                       "&supportsQueryFormats=true"
                      )

print("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=json"
                       "&geometryType=esriGeometryPolygon"
                       f"&objectIds={ids}"
                       "&returnIdsOnly=true"
                       "&supportsQueryFormats=true"
                      )

## try it with kmz:
ids=dd
kmzTest = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=KMZ"
                       f"&objectIds={ids}"
                       )

with open('test.kmz', 'wb') as kf:
    kf.write(kmzTest.content)

## that didn't work...the file is essentially empty. 

## they also list something about esri shape file format..

ids=dd
kmzTest = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=kmz"
                       "&geometryType=esriGeometryPolygon"
                       f"&objectIds={ids}"
                       )

with open('test.kmz', 'wb') as kf:
    kf.write(kmzTest.content)

mv test.kmz test.gz
gunzip test.kmz
## this is mostly empty. Why?


ids=dd
esriTest = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=lyr"
                       f"&objectIds={ids}"
                       )

with open('test.lyr', 'wb') as kf:
    kf.write(esriTest.content)
## nope, format unsupported, request denied


## is the problem simpler when we explicitly request polygons?
ids=dd
test = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=json"
                       "&geometryType=esriGeometryPolygon"
                       f"&objectIds={ids}"
                      )

## this is so close to a geojson...frustrating...

## maybe it supports geojson?
ids=dd
test = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=geojson"
                       "&geometryType=esriGeometryPolygon"
                       f"&objectIds={ids}"
                      )
## nope


ids=dd
test = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=pjson"
                       "&geometryType=esriGeometryPolygon"
                       f"&objectIds={ids}"
                      )
##

test.content

with open('test.json', 'wb') as f:
    f.write(test.content)

## still looks like our best hope is json

ids=dd
test = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=json"
                       "&geometryType=esriGeometryPolygon"
                       f"&objectIds={ids}"
                      )

##

with open('test.html', 'wb') as f:
    f.write(test.content)
## ## for jsons
## aa = json.loads(first2.text)
## pprint.pprint(aa) ## looks okay
## ## but how to get this to geojson? or anything that our software can use?
## ## their jsons don't look easilt 

## these strings are 8-bit, for accents etc,
## to recover them:
b'PEQUE\xc3\x91A'.decode()

## tonight 

## - break up series into <1000 chunks, 
## - make requests, merge 
## - start github repo, post everything

## okay, start over:


import requests, re, json, pprint, geojson, os
import pandas as pd
import geopandas as gpd
import shapely.geometry as sg
from matplotlib import pyplot as plt; plt.ion()
from descartes.patch import PolygonPatch


concIDs = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
            "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
            "MapServer/0/query?where=0%3D0&outFields=%2A&f=json&returnIdsOnly=true")

aa = concIDs.text.split(',')
bb = pd.Series(aa)
allIDs = bb.drop([0,1,bb.index[-1]]).reset_index(drop=True)
cc = allIDs.iloc[0:10].to_string(index=False) 
patt = re.compile('\n +')
concs2get = patt.sub(',', cc).strip()

test = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=json"
                       "&geometryType=esriGeometryPolygon"
                       f"&objectIds={concs2get}"
                      )
## that is a successful request, but gives the generic json objects,
## these are great, we can get teh coordinates out of them, but we 
## will have do some not-insignificant data munging to make them work. 

## if we build the html for a query, by viewing the followng in a browser:

https://geovisorm.controlrecursosyenergia.gob.ec/arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/MapServer/0/query

## we can see the list of available file formats:

HTML, JSON, AMF, KMZ

## the kmz is the only explicitly "mapping" file format, 
## but when I request this:

test = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A"
                       "&f=kmz"
                       "&geometryType=esriGeometryPolygon"
                       f"&objectIds={concs2get}"
                      )


## the result is a titled-but-empty kmz. The uncompressed kml 
## contains no real information:

with open('testKMZ.gz', 'wb') as f:
    f.write(test.content)

## in bash
gunzip testKMZ.gz

## works, so let's go ahead and grab them all while  
## we want to break this up to say 900-member lists

brokenUpIDs = {'0-899':allIDs.iloc[0:900],
      '900-1799':allIDs.iloc[900:1800],
      '1800-2699':allIDs.iloc[1800:2700],
      '2700-3599':allIDs.iloc[2700:3600],
      '3600-4499':allIDs.iloc[3600:4500],
      '4500-5399':allIDs.iloc[4500:5400],
      '5400-6299':allIDs.iloc[5400:6300],
      '6300-7199':allIDs.iloc[6300:7200],
      '7200-end':allIDs.iloc[7200:]}



for i in aa.brokenUpIDs():
    print(aa[i])




def makeConcList(pieceOfRequest):
    clean = pieceOfRequest.to_string(index=False)
    patt = re.compile('\n +')
    concs2get = patt.sub(',', clean).strip()
    return(concs2get)



for i in brokenUpIDs.keys():
    concs2get = makeConcList(brokenUpIDs[i])
    print(f'{i}.json')
    concReq = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                           "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                           "MapServer/0/query?where=0%3D0"
                           "&outFields=%2A&f=json"
                           "&geometryType=esriGeometryPolygon"
                           f"&objectIds={concs2get}"
                          )
    with open(f'{i}.json', 'wb') as f:
        f.write(concReq.content)

## for reason, that still times out...why?

grep -o -w "dpa_despro" 900-1799.json | wc -l ## still only 900 geometries...


## start over with 500 geometries per request...

brokenUpIDs500 = {'0-499':allIDs.iloc[0:500],
      '500-999':allIDs.iloc[500:1000],
      '1000-1499':allIDs.iloc[1000:1500],
      '1500-1999':allIDs.iloc[1500:2000],
      '2000-2499':allIDs.iloc[2000:2500],
      '2500-2999':allIDs.iloc[2500:3000],
      '3000-3499':allIDs.iloc[3000:3500],
      '3500-3999':allIDs.iloc[3500:4000],
      '4000-4499':allIDs.iloc[4000:4500],
      '4500-4999':allIDs.iloc[4500:5000],
      '5500-5999':allIDs.iloc[5500:6000],
      '6000-6499':allIDs.iloc[6000:6500],
      '6500-6999':allIDs.iloc[6500:7000],
      '7000-end':allIDs.iloc[7000:]}

for i in brokenUpIDs500.keys():
    concs2get = makeConcList(brokenUpIDs500[i])
    print(f'{i}.json')
    concReq = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                           "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                           "MapServer/0/query?where=0%3D0"
                           "&outFields=%2A&f=json"
                           "&geometryType=esriGeometryPolygon"
                           f"&objectIds={concs2get}"
                          )
    with open(f'{i}.json', 'wb') as f:
        f.write(concReq.content)

## that worked better.
## now how to convert these to geojsons...

## can we bring in one of these files and parse it?

aa = json.load(open('0-499.json', 'r'))

aa.keys()

aa['displayFieldName'] ## don't need
aa['fieldAliases'] ## explanation of the field types, don't think we need this?
aa['geometryType'] ## 'esri geometry polygon', as requested, not needed
aa['spatialReference'] 
## {'wkid': 24877, 'latestWkid': 24877}, will need this in the geojson, it's PSAD_1956_UTM_Zone_17S, =  EPSG:24877
aa['fields'] ## explanation of GIS table variable types
aa['features'] ## this is the meat of it, the polygons in the form of esri rings, with their associated table data


pprint.pprint(aa)

## we can write out the whole thing so:
with open('pretty0-499.txt', 'w') as f:
    f.write( pprint.pformat(aa) )

## but we may want to extract just the features
## keep it pretty for the moment, hope this doesn't cause problems?

pprint.pprint(aa['features'] )

with open('pretty0-499_features.txt', 'w') as f:
    f.write( pprint.pformat(aa['features'] ) )



## but for the moment, we probably want to extract the features, and 
## use the rings as polygons in a geojson.
## geojson technically won't take this projection, but I think we 
## can fudge it so qgis and geopandas will accept it. 

## I think we will want to create a feature collection, where each
## concession is a feature, with a geometry type = polygon (maybe multipolygon?), 
## coordinates pulled from the rings object of the original json,
## and the varies table data placed into the properties object

"type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "geometry": {
        "type": "Point",
        "coordinates": [102.0, 0.5]
      },
      "properties": {
        "prop0": "value0"
      }




## I assume we're going to have to build 
## some dictionaries and write them out with the
## json or geojson module
## for one feature from the original json:

aa['features'][0]

aa['features'][100]

[ tuple(i) for i in oneEsri['geometry']['rings'][0] ]

## points for geojson need to be (x,y), sometimes these UTM cses don't 
## report that way...

oneEsri=aa['features'][0]
oneEsri['geometry']['rings'][0][0]
## [762500, 9542200] looks right

pprint.pprint(oneEsri)

## so how do we convert this into a dictionary? We need to rename the 
## "attributes" key to "properties"
## and change the "rings" key to "coordinates"
## the first and last coordinates of the geojson must match...check.
## in geojsons, the first linear ring is the outside of the polygon,
## and all further rings are holes in the polygon. 
## not sure what their setup is in the esri json object, but it's
## a good bet that they are following this protocol, given that 
## they seem to be generally following all the other norms of 
## linear-rings/polygons.
## I'm sure that with 7000+ concessions, we will find both multipolygons
## and polygons with holes. 
## but the vast majority should be simple polygons. 

## an explanation of the esri REST api json objects is here:
https://geovisorm.controlrecursosyenergia.gob.ec/arcgis/sdk/rest/index.html#//02ss0000008m000000


## if we assume no holes or extra polygons, how do we convert one esri json feature to one geojson feature?

oneEsri=aa['features'][0]
anotherEsri=aa['features'][400]

oneEsri
anotherEsri

oneGJfeature = geojson.Feature()
oneGJfeature['geometry'] = {"coordinates": [ tuple(i) for i in oneEsri['geometry']['rings'][0] ] }
oneGJfeature['properties'] = oneEsri['attributes']

anotherGJfeature = geojson.Feature()
anotherGJfeature['geometry'] = {"coordinates": [ tuple(i) for i in anotherEsri['geometry']['rings'][0] ] }
anotherGJfeature['properties'] = anotherEsri['attributes']
FC = geojson.FeatureCollection([oneGJfeature, anotherGJfeature])

pprint.pprint(FC)

## some non-canonical geojsons addd in a note about projections:
FC["crs"] = { "type": "name", "properties": { "name": "urn:ogc:def:crs:EPSG::32717" } }

## and can we export this as a geojson?
with open('test.geojson', 'w') as f:
   geojson.dump(FC, f)


## and that's not working. maybe if we run the polygons through shapely?



##ext = [ tuple(i) for i in oneEsri['geometry']['rings'][0] ]
## or 
ext = [ tuple(i) for i in anotherEsri['geometry']['rings'][0] ]
polygon = sg.Polygon(ext, [])

plt.ion()
fig, ax = plt.subplots()
patch = PolygonPatch(polygon, facecolor='green')
ax.add_patch(patch)
ax.set_xlim(polygon.bounds[0],polygon.bounds[2])
ax.set_ylim(polygon.bounds[1],polygon.bounds[3])

## looks good. Why does it say it is not closed?

polygon.area
polygon.is_valid ## true
polygon.is_closed ## false

## not sure. Plot looks good for both polygons, matches the arcom site, maybe not a problem.

## well, if we assume these are good polygons, how to we make a geojson file out of them?


sg.mapping(polygon)



oneGJfeature = geojson.Feature()
ext = [ tuple(i) for i in oneEsri['geometry']['rings'][0] ]
polygon = sg.Polygon(ext, [])
oneGJfeature['geometry'] = sg.mapping(polygon)
oneGJfeature['properties'] = oneEsri['attributes']

anotherGJfeature = geojson.Feature()
ext = [ tuple(i) for i in anotherEsri['geometry']['rings'][0] ]
polygon = sg.Polygon(ext, [])
anotherGJfeature['geometry'] = sg.mapping(polygon)
anotherGJfeature['properties'] = anotherEsri['attributes']

FC = geojson.FeatureCollection([oneGJfeature, anotherGJfeature])

FC["crs"] = { "type": "name", "properties": { "name": "urn:ogc:def:crs:EPSG::32717" } }

with open('test.geojson', 'w') as f:
   geojson.dump(FC, f)

## okay, qgis is accepting that. 

## how about geopandas?

testGJ = gpd.read_file('/home/daniel/Documents/LosCed/getConcessionScripts/test.geojson')

testGJ.plot()

## music to my eyes. 

## so how do we scale up to do the entire esri json file?

## make a loop out of this

allEsriFeatures = json.load(open('0-499.json', 'r'))['features']
allGJFeatures = []

for i in allEsriFeatures:
    GJfeature_i = geojson.Feature()
    ext_i = [ tuple(j) for j in i['geometry']['rings'][0] ]
    polygon_i = sg.Polygon(ext_i, [])
    GJfeature_i['geometry'] = sg.mapping(polygon_i)
    GJfeature_i['properties'] = i['attributes']
    allGJFeatures.append(GJfeature_i)

FC = geojson.FeatureCollection(allGJFeatures)
FC["crs"] = { "type": "name", "properties": { "name": "urn:ogc:def:crs:EPSG::32717" } }

with open('test.geojson', 'w') as f:
   geojson.dump(FC, f)

## that looks good. how can we loop through all files?

patt = re.compile('[0-9]+-.*\.json')
esriJsons = [ i for i in os.listdir() if patt.search(i) ]
allGJFeatures = []

for name in esriJsons:
    json_i = json.load(open(name, 'r'))['features']
    for i in json_i:
        GJfeature_i = geojson.Feature()
        ext_i = [ tuple(j) for j in i['geometry']['rings'][0] ]
        polygon_i = sg.Polygon(ext_i, [])
        GJfeature_i['geometry'] = sg.mapping(polygon_i)
        GJfeature_i['properties'] = i['attributes']
        allGJFeatures.append(GJfeature_i)

FC = geojson.FeatureCollection(allGJFeatures)
FC["crs"] = { "type": "name", "properties": { "name": "urn:ogc:def:crs:EPSG::32717" } }

with open('test.geojson', 'w') as f:
   geojson.dump(FC, f)


testGJ = gpd.read_file('test.geojson')

testGJ.plot()

## some of these are missing, right? I only see 6836 concessions, and there should be 7000+.

## for example, codigo 401133 is on the arcom site but missing here. Why?

grep '"nam":"401133"' -r

grep '"nam":"290999"' -r -o

grep '"40000339"' -r -o

grep '"nam":"40000339"' -r -o

## it looks like at least this concession (401133) was simply left out of the request results.

## are they in the names file for the request?

grep "401133" concIDs.txt ## nope. but maybe that's the wrong key to search 

grep "290999" concIDs.txt ## nope. so the ids that the REST api uses are different, 
## not the "nam" field, which is the codigo catastral

## however, I still have more id strings in my request than I have concessions in my shapefile.

## so two mysteries to solve. 

grep '"nam":"290999"' -r -o

grep "," concIDs.txt -o | wc -l

## well, so much for the slam dunk. Back to this later. 


#############################

## start over. Here is our pipeline from restful request to geojson:

import requests, re, json, pprint, geojson, os
import pandas as pd
import geopandas as gpd
import shapely.geometry as sg
from matplotlib import pyplot as plt; plt.ion()
from descartes.patch import PolygonPatch

## step one request all ids
concIDs = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
        "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/MapServer/0/" 
        "query?where=0%3D0"
        "&outFields=%2A"
        "&f=json"
        "&returnIdsOnly=true"
        )

## step two reformat these ids and break up into 500-item lists
aa = concIDs.text.split(',')
bb = pd.Series(aa)
allIDs = bb.drop([0,1,bb.index[-1]]).reset_index(drop=True)
cc = allIDs.to_string(index=False) 
patt = re.compile('\n +')
concs2get = patt.sub(',', cc).strip()

## make that into a function:
def makeConcList(pieceOfRequest):
    clean = pieceOfRequest.to_string(index=False)
    patt = re.compile('\n +')
    concs2get = patt.sub(',', clean).strip()
    return(concs2get)

brokenUpIDs500 = {'0-499':allIDs.iloc[0:500],
      '500-999':allIDs.iloc[500:1000],
      '1000-1499':allIDs.iloc[1000:1500],
      '1500-1999':allIDs.iloc[1500:2000],
      '2000-2499':allIDs.iloc[2000:2500],
      '2500-2999':allIDs.iloc[2500:3000],
      '3000-3499':allIDs.iloc[3000:3500],
      '3500-3999':allIDs.iloc[3500:4000],
      '4000-4499':allIDs.iloc[4000:4500],
      '4500-4999':allIDs.iloc[4500:5000],
      '5500-5999':allIDs.iloc[5500:6000],
      '6000-6499':allIDs.iloc[6000:6500],
      '6500-6999':allIDs.iloc[6500:7000],
      '7000-end':allIDs.iloc[7000:]}

## step three request these, 500 at a time:

for i in brokenUpIDs500.keys():
    concs2get = makeConcList(brokenUpIDs500[i])
    print(f'{i}.json')
    concReq = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                           "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                           "MapServer/0/query?where=0%3D0"
                           "&outFields=%2A&f=json"
                           "&geometryType=esriGeometryPolygon"
                           f"&objectIds={concs2get}"
                          )
    with open(f'{i}.json', 'wb') as f:
        f.write(concReq.content)


## now we have 14 little json files that should have all of the esri polygons in them
## loop through these files, convert the concessions to shapely polygons then
## stick them in one big geojson:

patt = re.compile('[0-9]+-.*\.json')
esriJsons = [ i for i in os.listdir() if patt.search(i) ]
allGJFeatures = []


for name in esriJsons:
    json_i = json.load(open(name, 'r'))['features']
    for i in json_i:
        GJfeature_i = geojson.Feature()
        ext_i = [ tuple(j) for j in i['geometry']['rings'][0] ]
        polygon_i = sg.Polygon(ext_i, [])
        GJfeature_i['geometry'] = sg.mapping(polygon_i)
        GJfeature_i['properties'] = i['attributes']
        allGJFeatures.append(GJfeature_i)

FC = geojson.FeatureCollection(allGJFeatures)
FC["crs"] = { "type": "name", "properties": { "name": "urn:ogc:def:crs:EPSG::32717" } }

with open('test2.geojson', 'w') as f:
   geojson.dump(FC, f)

############################################

## okay, just curious, do we always get the exact same number of concessions 
## when we request their names?

concIDs.text.count(',') ## yes, =7335, always

## and does the above process always yield the same polygons?
## for instance

testGJ1 = gpd.read_file('test.geojson')
gj1Ax = testGJ1.plot()
testGJ2 = gpd.read_file('test2.geojson')
testGJ2.boundary.plot(color='green', ax=gj1Ax)

## it looks like the same polygons are missing in both, roughly

gj2Ax = testGJ2.boundary.plot(color='green')



testGJ1.shape

testGJ2.shape ## maybe not, there are three fewer in this latest file...hmmm

testGJ1.head()

testGJ1.nam
testGJ2.nam


## in gj1 but not gj2
aa = testGJ1.objectid.apply(lambda x: x in testGJ2.objectid.values)
testGJ1.objectid[~aa]

## in gj2 but not gj1
testGJ2.objectid[550] in testGJ1.objectid.values

## in gj2 but not gj1
aa = testGJ2.objectid.apply(lambda x: x in testGJ1.objectid.values)
testGJ2.objectid[~aa]

## so maybe this is stochastic. A few requests are failing here and 
## there...

## so what's in our objectIDs that's not in our polygons?

## numeric or string?
1402 in testGJ1.objectid.values
'1402' in testGJ1.objectid.values
140289999999999 in testGJ1.objectid.values
## numeric 


testGJ1.objectid.to_list()

'34821' in allIDs.values

34821 in testGJ1.objectid.to_list()

34821 in testGJ1.objectid.to_list()

## staying with our original geojson ("test.geojson")

bb = allIDs.astype('int64').apply(lambda x: x in testGJ1.objectid.to_list())
missingObjIDs = allIDs[~bb]

## great, what happens if we request these? 
## run these through the above

concs2get = makeConcList(missingObjIDs)

concReq = requests.get("https://geovisorm.controlrecursosyenergia.gob.ec/"
                       "arcgis/rest/services/Concesiones/CatastroMineroNacional_PSAD56/"
                       "MapServer/0/query?where=0%3D0"
                       "&outFields=%2A&f=json"
                       "&geometryType=esriGeometryPolygon"
                       f"&objectIds={concs2get}"
                      )


with open('missingObj.json', 'wb') as f:
    f.write(concReq.content)

missingJSON = json.load(open('missingObj.json', 'r'))['features']

allGJFeatures = []
for i in missingJSON:
    GJfeature_i = geojson.Feature()
    ext_i = [ tuple(j) for j in i['geometry']['rings'][0] ]
    polygon_i = sg.Polygon(ext_i, [])
    GJfeature_i['geometry'] = sg.mapping(polygon_i)
    GJfeature_i['properties'] = i['attributes']
    allGJFeatures.append(GJfeature_i)

FC = geojson.FeatureCollection(allGJFeatures)
FC["crs"] = { "type": "name", "properties": { "name": "urn:ogc:def:crs:EPSG::32717" } }

with open('missingObj.geojson', 'w') as f:
   geojson.dump(FC, f)

testGJ = gpd.read_file('test.geojson')
gjAx = testGJ.boundary.plot(color='green')

missingObjGJ = gpd.read_file('missingObj.geojson')
missingObjGJ.plot(color='red', ax=gjAx)

missingObjGJ.shape

## great, combine them:

draftConcessions = pd.concat([testGJ,missingObjGJ])

ax = draftConcessions.boundary.plot()
missingObjGJ.plot(color='red', ax=ax)

## 4 columns too many. Weird.
## now we are bigger than the request?
concIDs.text.count(',') ## 7335
draftConcessions.shape  ## 7339
## any duplicates?

draftConcessions.objectid.duplicated() ## nope, weird

## meh. not sure. Need a break.

## maybe Roo and Mireya would be willing to take a look at it.

import fiona
fiona.supported_drivers  

draftConcessions.to_file('draftConcessions.05.2022.shp')

draftConcessions.to_file('draftConcessions.05.2022.geojson', driver='GeoJSON')

## for some reason, that is not exporting the attributes, just the 
## the polygons.

## ok, works now. Not sure what happened there..

########## analysis ###########

## the aussies would like kml files for each of their australian companies

import fiona
import pandas as pd
import geopandas as gpd
from matplotlib import pyplot as plt; plt.ion()
draftConcessions = gpd.read_file('draftConcessions/draftConcessions.05.2022.geojson')
draftConcessions['ttm'] = draftConcessions['ttm'].str.strip()
fiona.supported_drivers['KML'] = 'rw'

draftConcessions.columns

#### BHP ####

draftConcessions.where(draftConcessions['com'] == 'CERRO QUEBRADO S.A')

sum(draftConcessions['com'] == 'CERRO QUEBRADO S.A') ## nothing...?
'CERRO QUEBRADO S.A' in  draftConcessions['com'].unique().tolist()
## can't find this subsidiary

## others:

company = 'ECUADORFORTESCUE S.A.'
company = 'HANRINE ECUADORIAN EXPLORATION AND MINING S.A'
company = 'NEWCRESTECUADOR S A'
company = 'CARNEGIE RIDGE RESOURCES S.A'

company = 'CRUZ DEL SOL CSSA S.A.'

(draftConcessions == company).any() ## not in there??

(draftConcessions == 'PALMA REAL 4').any() ## in 'com'

## so something more like this:
draftConcessions[draftConcessions.com == 'PALMA REAL 4']

draftConcessions[draftConcessions.com == 'PALMA REAL 2']

draftConcessions[draftConcessions.com == 'BUEY']

draftConcessions[draftConcessions.com == 'BUEY'].iloc[0].loc['ttm']

## looks like we really want ttm for our company names:

(draftConcessions['ttm'] == "CERRO QUEBRADO S.A").any() ## nope?

draftConcessions['ttm'].str.contains( "CERRO QUEBRADO S.A").any() ## ah whitespace issues


## we will need to clean this, there could be other problems.

draftConcessions['ttm'].str.contains( "CERRO QUEBRADO S.A").to_list()
ttmFilter = draftConcessions['ttm'].str.contains("CERRO QUEBRADO S.A").astype('bool')


ttmFilter = draftConcessions['ttm'].str.contains("CERRO QUEBRADO").astype('bool')

draftConcessions[ttmFilter]

draftConcessions[ttmFilter].shape

sum(aa) ## only 11, should be more? 

## maybe we should take this apart. The "Concession ID" column in the aussie data 
## may be what we need, for each 

cerroQs = pd.Series([
'PALMA REAL 4',
'PALMA REAL 2',
'PALMA REAL 5',
'SABALETA 4',
'SAN FRANCISCO',
'SANTA TERESA',
'PALMA REAL 1',
'SABALETA 2',
'PALMA REAL 1',
'SANTA TERESA 2',
'SABALETA 3',
'PALMA REAL 4',
'BUEY',
'PALMA REAL 2',
])

## check all of these 

## all are found somewhere at least once

[ draftConcessions['com'].str.contains(i).any() for i in cerroQs ]

cerroQs.apply(lambda x:  draftConcessions['com'].str.contains(x).any()) 

cerroQs.apply(lambda x:  draftConcessions['ttm'].str.contains(x).any()) ## only one, 4
cerroQs[4] ## SAN FRANCISCO, could be anything, ignore

## "com" is what we need, using the "Concession ID". Rebuild our groups from this. 

i = 'BUEY'
filtComp = draftConcessions['com'].str.contains(i).astype('bool')
iDF = draftConcessions[filtComp]

i = 'BUEY'

def getTTMs(ttm_i):
    filtComp_i = draftConcessions['com'].str.contains(ttm_i).astype('bool')
    i_DF = draftConcessions[filtComp_i]
    return(i_DF)

getTTMs(i)

aa = pd.DataFrame()
for i in cerroQs:
    aa = pd.concat([aa, getTTMs(i)])

aa['ttm']

aa[['nam','ttm','com','tipo_mineral']]

aa[['nam','ttm','com','tipo_mineral','ach']]

## huh, now we have the opposite problem. This is too big. 
## would some of these problems go away if we cleaned up the white space?

draftConcessions['ttm'] = draftConcessions['ttm'].str.strip()
(draftConcessions['ttm'] == "CERRO QUEBRADO S.A").any() ## now it works
sum(draftConcessions['ttm'] == "CERRO QUEBRADO S.A") ## still too few

cqFilt = draftConcessions['ttm'] == "CERRO QUEBRADO S.A" 
onlyCQdf = draftConcessions[cqFilt]

## so what are we missing? 

onlyCQdf['com']

len(onlyCQdf['com'])

len(cerroQs) ## 14

len(cerroQs.unique()) ## 11, looks like repeated names

len(set((cerroQs))) ## indeed, there are some repeats.

cerroQs[cerroQs.duplicated()] ## PALMA REAL 1,2, and 4 are 

## in the data from RIC:
## PALMA REAL 1 has exactly the same area in both cases, probably a duplicate
## PALMA REAL 2 also has exactly the same area in both cases, also probably a duplicate
## PALMA REAL 4 also has exactly the same area in both cases, also probably a duplicate

## so we're probably okay. 

## if we want to make a kml file out of these?

## there are rumors that fiona can do it. Let's try:

# Enable fiona driver
fiona.supported_drivers['KML'] = 'rw'

# Write to kml file
with fiona.Env():
    onlyCQdf.to_file('kmls/BHP.kml', driver='KML') 

## that seems to work.

#### ECUADORFORTESCUE S.A. ####

EFttmFilter = draftConcessions['ttm'].str.contains("ECUADORFORTESCUE S.A.").astype('bool')
EFdf = draftConcessions[EFttmFilter]

ecuadorforteConcNames = pd.Series(
["2C", "7B", "8O", "7H", "7F", "8H", "8K", "8L", "SANTA ANA", "7C", "8E", "7M", "7D", "8G",
"8J2", "8I", "10A", "7E", "7K", "8M", "8C", "8B", "2D", "7J", "7G", "7A", "8P", "8F", "2A",
"7I", "8D", "8A", "2B", "8N", "7L"]
)

ecuadorforteConcNames.isin(EFdf["com"]).all() ## all are represented, and the same length.

"7E" in EFdf["com"].values

EFdf.shape ## 35 rows, matches

ecuadorforteConcNames.duplicated().any()

ecuadorforteConcNames.isin(EFdf["com"]).all()
EFdf["com"].isin(ecuadorforteConcNames).all()

EFdf[["com","ttm","ach"]].sort_values(by='com')

EFdf.shape

## generally, looks right 

with fiona.Env():
    EFdf.to_file('kmls/ecuadorfortescue.kml', driver='KML') 

#### Hancock ####

subsid = "HANRINE ECUADORIAN EXPLORATION AND MINING S.A"
filename = "hancock"
#######
subsidFilter = draftConcessions['ttm'].str.contains(subsid).astype('bool')
df = draftConcessions[subsidFilter]
df.sort_values(by='com') ## concession names look right
df.shape  ## nine concessions, right

with fiona.Env():
    df.to_file(('kmls/' + filename + '.kml'), driver='KML') 



#### Newcrest ####

subsid = "NEWCRESTECUADOR S A"
filename = "newcrest"
#######
subsidFilter = draftConcessions['ttm'].str.contains(subsid).astype('bool')
df = draftConcessions[subsidFilter]
df.sort_values(by='com')
df.shape  
with fiona.Env():
    df.to_file(('kmls/' + filename + '.kml'), driver='KML') 


#### SolGold ####

## solgold has several subsidiaries

CARNEGIE RIDGE RESOURCES S.A
CRUZ DEL SOL CSSA S.A.
EXPLORACIONES NOVOMINING S.A.
GREEN ROCK RESOURCES GRR SA
VALLE RICO RESOURCES VRR SA

## should be 103 concessions, I think
## at least, that's how many the aussies have.

## loop it:

concs = [
    "CARNEGIE RIDGE RESOURCES S.A",
    "CRUZ DEL SOL CSSA S.A.",
    "EXPLORACIONES NOVOMINING S.A.",
    "GREEN ROCK RESOURCES GRR SA",
    "VALLE RICO RESOURCES VRR SA"
        ]


aa = gpd.GeoDataFrame(columns=draftConcessions.columns.to_list(), geometry='geometry')
for subsid in concs:
    print(subsid)
    subsidFilter = draftConcessions['ttm'].str.contains(subsid).astype('bool')
    df = draftConcessions[subsidFilter]
    df.sort_values(by='com')
    df.shape  
    aa = pd.concat([aa, df])

with fiona.Env():
    aa.to_file(('kmls/solgold.kml'), driver='KML') 

## that didn't work. the kml is really weird. 
## the x coordinates are really weird
## the y axis look okay, but the x coordinates are really strange.

## the geopanda plots just fine, but won't export 

## maybe qgis will do it for us?

aa.to_file('solgold.geojson', driver='GeoJSON')

## nope. nothing plots

aa.is_valid.all() ## says all polygons good...

## ah, the projection is lost:

aa.crs ## nada

aa.crs = "EPSG:32717"

## did that fix it?

with fiona.Env():
    aa.to_file(('kmls/solgold.kml'), driver='KML') 

## indeed. 

## the last one, Valle Rico, seems like it is short one row...
vrcs = pd.Series(["SAN MIGUEL 4", "EL DESCANSO 1A", "SAN MIGUEL 1", "AGUSTIN 1", "SALINAS 3", "SALINAS 2", "LOS BANCOS", "YATUBI II", "ALAUSI 1", "EL TESORO 2", "AURORA 2", "ALAUSI 2", "SIGSAL 2", "SALAMPE", "AGUSTIN 2", "AGUSTIN 3", "LAS PAMPAS", "GUAYACANES 1", "SAN MIGUEL 3", "EL DESCANSO 1B", "SALINAS", "AGUSTIN 5", "SALINAS 1", "SIGSAL 1", "AGUSTIN 4", "SALINAS 4", "YATUBI I", "SAN MIGUEL 2", "AURORA 1", "LELIA", "GUAYACANES 2", "EL TESORO 1", "AURORA 1"])

vrcs.duplicated().any()

vrcs[vrcs.duplicated()] ## yup, looks like "Aurora 1" is doubled

## so not our problem. march on.

#### Tempus ####

concs = [ "CONDOR GOLD S.A.","MININGSOURCES S.A" ]
aa = gpd.GeoDataFrame(columns=draftConcessions.columns.to_list(), geometry='geometry')
aa.crs = "EPSG:32717"
for subsid in concs:
    print(subsid)
    subsidFilter = draftConcessions['ttm'].str.contains(subsid).astype('bool')
    df = draftConcessions[subsidFilter]
    df.sort_values(by='com')
    df.shape  
    aa = pd.concat([aa, df])

aa[["com","nam", "ttm","ach"]]

with fiona.Env():
    aa.to_file(('kmls/tempus.kml'), driver='KML') 

#### Titan Minerals ####

## should be 30
concs = [
    "CLOUDSTREET INTERNATIONAL CORP",
    "COMPAÑIA ELIPE S.A.",
    "HELLES MINING CORP.",
    "MOORO MINING INC.",
    "NEK DEVELOPMENT CORP."
        ]

aa = gpd.GeoDataFrame(columns=draftConcessions.columns.to_list(), geometry='geometry')
aa.crs = "EPSG:32717"
for subsid in concs:
    print(subsid)
    subsidFilter = draftConcessions['ttm'].str.contains(subsid).astype('bool')
    df = draftConcessions[subsidFilter]
    df.sort_values(by='com')
    df.shape  
    aa = pd.concat([aa, df])

with fiona.Env():
    aa.to_file(('kmls/titanMinerals.kml'), driver='KML') 


#### Pelorus Minerald Limited ####

concs = [
    "BULLA RESOURCES CORP",
    "HARTOG S.A.S.",
    "LONE PINE S.A.S.",
    "ROUND HOUSE MINING INC",
    "THIRD RIDGE CORP"
        ]


aa = gpd.GeoDataFrame(columns=draftConcessions.columns.to_list(), geometry='geometry')
aa.crs = "EPSG:32717"
for subsid in concs:
    print(subsid)
    subsidFilter = draftConcessions['ttm'].str.contains(subsid).astype('bool')
    df = draftConcessions[subsidFilter]
    df.sort_values(by='com')
    df.shape  
    aa = pd.concat([aa, df])

## I have one more than they...

## this is their list:
pelorusCom = pd.Series(["MACHAY ","BETHZABETH ","SAICHUMA I ","EL SALVADOR X 3 ","LA DURA ","LA CALERA ","EL RETAZO 3",
"LOS LAURELES 2 ","NUEVA ESPERANZA 2 ","NUEVA ESPERANZA ","ANA MICHELLE ","EL SOROCHE UNIFICADO",
"NUEVA ESPERANZA3 ","SUCA 4 ","SUCA ","SAN ANTONIO DE PADUA ","NUEVA ESPERANZA 6 ","LA ENVIDIA", 
"EL TABLON ","MARA 8 ","SAN JOSE 2 ","EL TABLON 1 ","RESUC 4 ","RUTH ","IAM ZARUMA"]).str.strip()

aa[~aa['com'].isin(pelorusCom)] ## all Round house concessions: 

"MINANCA"
"BARBASCO UNIFICADO"
"BARBASCO 1A"


draftConcessions[draftConcessions['com'].str.contains("BARBASCO").astype('bool')][["com","nam", "ttm","ach"]]
## interesting, there is a BARBASCO 1 and a BARBASCO 1A. 
## most of the Barbasco's belong to the Helles mining corporation,
## which is a subsidiary of Titan Minerals, above. 
## but these two belong to Round house, subsidiary of Pelorus
## both are very small

pelorusCom[~pelorusCom.isin(aa['com'])] 

pelorusCom[~pelorusCom.isin(aa['com'])] ## and they find two concessions not in my list. 
## weird and weird. these are: "MACHAY" and "EL SOROCHE UNIFICADO".

draftConcessions['ttm']

draftConcessions['com'].str.contains("MACHAY").any()

machay = draftConcessions[draftConcessions['com'].str.contains("MACHAY").astype('bool')]

machay[["com","nam", "ttm","ach"]] ## owner of this is now SOCIEDAD CIVIL MINERA GOLDMINS

soroche = draftConcessions[draftConcessions['com'].str.contains("EL SOROCHE UNIFICADO").astype('bool')]

## anyway, I can only report what these latest data say, so make the kml 
## with the three additional concessions I found, minus the two whose 
## ownership seems to have shifted away from the Pelorus group 

with fiona.Env():
    aa.to_file(('kmls/pelorusMinerals.kml'), driver='KML') 

#### NEWCREST + LUNDIN GOLD ####

concs = [ "AURELIAN ECUADOR S.A.","AURELIANMENOR S.A." ]

aa = gpd.GeoDataFrame(columns=draftConcessions.columns.to_list(), geometry='geometry')
aa.crs = "EPSG:32717"
for subsid in concs:
    print(subsid)
    subsidFilter = draftConcessions['ttm'].str.contains(subsid).astype('bool')
    df = draftConcessions[subsidFilter]
    df.sort_values(by='com')
    df.shape  
    aa = pd.concat([aa, df])

## I get two more than they do for this.
## their concession names:

newLunCom = pd.Series(["CONDESA","LA ZARZA","PRINCESA I","VALLE DEL INCA 2","RIO ZARZA 2","GUACAMAYO","SOBERANO",
"MARQUESA","BARON","REINA","CACIQUE","SOBERANA","LAS ORQUIDEAS","REY","EMPERADOR","CACIQUE 1",
"BARONESA","SOBERANO 3","PRINCIPE","MARQUES","VIZCONDE","VIZCONDE 1"])

aa[~aa['com'].isin(newLunCom)] ## 3 concessions, small, all construction materials, all owned by Aurelian. Maybe too small, this is why they were left out?

## any they found that I didn't? 

newLunCom[~newLunCom.isin(aa['com'])] ## just one SOBERANO 3


soberano = draftConcessions[draftConcessions['com'].str.contains("SOBERANO 3").astype('bool')]

soberano[["com","nam", "ttm","ach"]] ## owner of this is now URENA QUEZADA CELSO AMABLE, nam=50001172

## so we gained 3, lost 1, so I come out 2 ahead on this from their results:

with fiona.Env():
    aa.to_file(('kmls/NewCrestLundin.kml'), driver='KML') 

#### NEWCREST + CORNERSTONE RESOURCES ####

subsid =  "CAÑABRAVA MINING SA" 

subsidFilter = draftConcessions['ttm'].str.contains(subsid).astype('bool')

df = draftConcessions[subsidFilter]
df.sort_values(by='com')
df.shape  

with fiona.Env():
    df.to_file(('kmls/NewcrestCornerstone.kml'), driver='KML') 

#### SUNSTONE METALS + CORNERSTONE RESOURCES ####

subsid = "LA PLATA MINERALES"
subsidFilter = draftConcessions['ttm'].str.contains(subsid).astype('bool')
df = draftConcessions[subsidFilter]

df.sort_values(by='com')
df.shape  

## I have one more than they, called "CUEVA DEL LEON", nam=60000437
## very small, probably why its not included

with fiona.Env():
    df.to_file(('kmls/SunstoneCornerstone.kml'), driver='KML') 

## so that leaves 

#### BHP + LUMINEX RESOURCES ####

subsid = "CERRO YATSUR SA"
subsidFilter = draftConcessions['ttm'].str.contains(subsid).astype('bool')
df = draftConcessions[subsidFilter]
df.sort_values(by='com')
df.shape  

## all in order there

with fiona.Env():
    df.to_file(('kmls/BHPLuminex.kml'), driver='KML') 


